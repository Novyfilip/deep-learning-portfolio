{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent and Momentum\n",
    "\n",
    "This notebook explores gradient descent optimization from scratch, visualizing how different parameters affect convergence. I also implement momentum to show how it helps navigate tricky loss landscapes.\n",
    "\n",
    "**Topics covered:**\n",
    "- Gradient descent implementation\n",
    "- Effect of step size and loss surface shape on convergence\n",
    "- Momentum-based optimization\n",
    "- Comparison on the Beale function (a classic optimization test case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Gradient Descent\n",
    "\n",
    "I'll start with a simple quadratic function: $f(x_1, x_2) = \\frac{1}{2}(x_1^2 + a \\cdot x_2^2)$\n",
    "\n",
    "The parameter $a$ controls how \"stretched\" the loss surface is. When $a$ is large, the surface is much steeper in the $x_2$ direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function and its gradient\n",
    "def f_quadratic(x: np.ndarray, a: float) -> float:\n",
    "    return 0.5 * (x[0]**2 + a * x[1]**2)\n",
    "\n",
    "def df_quadratic(x: np.ndarray, a: float) -> np.ndarray:\n",
    "    #gradient is [x1, a*x2]\n",
    "    return np.array([x[0], a * x[1]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_quadratic(a: float, step_size: float, num_steps: int) -> list:\n",
    "    \"\"\"Runs gradient descent on the quadratic function, starting from (256, 1).\"\"\"\n",
    "    x = np.array([256.0, 1.0])\n",
    "    path = [x.copy()]\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        g = df_quadratic(x, a)\n",
    "        x = x - step_size * g\n",
    "        path.append(x.copy())\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function visualizes the optimization path on a contour plot\n",
    "def visualize_quadratic(a: float, path: list, ax=None) -> None:\n",
    "    y_range = 10\n",
    "    x = np.arange(-257, 257, 0.1)\n",
    "    y = np.arange(-y_range, y_range, 0.1)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    z = 0.5 * (xx**2 + a * yy**2)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    ax.contourf(xx, yy, z, cmap='PuBu_r')\n",
    "    ax.plot([p[0] for p in path], [p[1] for p in path], 'r.--', markersize=4, label='GD path')\n",
    "    ax.plot([0], [0], 'rs', markersize=8, label='Optimum')\n",
    "    ax.set_xlim([-257, 257])\n",
    "    ax.set_ylim([-y_range, y_range])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of the parameter $a$ on convergence\n",
    "\n",
    "When $a$ is small, the loss surface is nearly circular and gradient descent converges nicely. As $a$ increases, the surface becomes elongated and gradient descent starts to oscillate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing different values of a with fixed step size\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 9))\n",
    "\n",
    "a_values = [1, 4, 16, 64, 128, 256]\n",
    "\n",
    "for ax, a in zip(axes.flatten(), a_values):\n",
    "    #i had to reduce step size for larger a to prevent divergence\n",
    "    step_size = 0.01 if a > 64 else 0.1\n",
    "    path = gradient_descent_quadratic(a=a, step_size=step_size, num_steps=40)\n",
    "    visualize_quadratic(a=a, path=path, ax=ax)\n",
    "    ax.set_title(f'a={a}, step={step_size}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Higher values of $a$ require smaller step sizes. This is because the gradient in the $x_2$ direction becomes much larger, causing overshooting if the step size is too big.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Gradient Descent with Momentum\n",
    "\n",
    "To handle tricky loss landscapes, I implemented momentum. The idea is to accumulate a \"velocity\" that smooths out the optimization trajectory:\n",
    "\n",
    "$$v_{t+1} = \\beta v_t + (1-\\beta) \\nabla f(x_t)$$\n",
    "$$x_{t+1} = x_t - \\eta v_{t+1}$$\n",
    "\n",
    "I'll test this on the Beale function, which has a nasty curved valley that makes vanilla gradient descent struggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Beale function - a classic optimization benchmark\n",
    "#it has a global minimum at (3, 0.5)\n",
    "def f_beale(x: np.ndarray) -> float:\n",
    "    return ((1.5 - x[0] + x[0]*x[1])**2 + \n",
    "            (2.25 - x[0] + x[0]*x[1]**2)**2 + \n",
    "            (2.625 - x[0] + x[0]*x[1]**3)**2)\n",
    "\n",
    "def df_beale(x: np.ndarray) -> np.ndarray:\n",
    "    #the gradient (provided in the exercise, this would be painful to derive by hand)\n",
    "    d1 = (2*(1.5 - x[0] + x[0]*x[1])*(-1 + x[1]) + \n",
    "          2*(2.25 - x[0] + x[0]*x[1]**2)*(-1 + x[1]**2) + \n",
    "          2*(2.625 - x[0] + x[0]*x[1]**3)*(-1 + x[1]**3))\n",
    "    d2 = (2*(1.5 - x[0] + x[0]*x[1])*(x[0]) + \n",
    "          2*(2.25 - x[0] + x[0]*x[1]**2)*(2*x[0]*x[1]) + \n",
    "          2*(2.625 - x[0] + x[0]*x[1]**3)*(3*x[0]*x[1]**2))\n",
    "    return np.array([d1, d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x0: np.ndarray, grad_fn, step_size: float, num_steps: int) -> list:\n",
    "    \"\"\"Vanilla gradient descent.\"\"\"\n",
    "    x = x0.copy()\n",
    "    path = [x.copy()]\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        g = grad_fn(x)\n",
    "        x = x - step_size * g\n",
    "        path.append(x.copy())\n",
    "    \n",
    "    return path\n",
    "\n",
    "def gradient_descent_momentum(x0: np.ndarray, grad_fn, step_size: float, num_steps: int, beta: float) -> list:\n",
    "    \"\"\"Gradient descent with momentum.\"\"\"\n",
    "    x = x0.copy()\n",
    "    v = np.zeros_like(x)  #velocity starts at zero\n",
    "    path = [x.copy()]\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        g = grad_fn(x)\n",
    "        v = beta * v + (1 - beta) * g  #update velocity\n",
    "        x = x - step_size * v          #update position\n",
    "        path.append(x.copy())\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this visualizes both paths on the Beale function\n",
    "def visualize_beale(gd_path: list, momentum_path: list) -> None:\n",
    "    x = np.arange(-4.5, 4.5, 0.01)\n",
    "    y = np.arange(-4.5, 4.5, 0.01)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    z = f_beale(np.array([xx, yy]))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.contourf(xx, yy, z, locator=ticker.LogLocator(), cmap='PuBu_r', levels=np.logspace(-2, 5, 35))\n",
    "    \n",
    "    ax.plot([p[0] for p in gd_path], [p[1] for p in gd_path], 'r.--', markersize=4, label='Vanilla GD')\n",
    "    ax.plot([p[0] for p in momentum_path], [p[1] for p in momentum_path], 'm.--', markersize=4, label='With Momentum')\n",
    "    ax.plot(3, 0.5, 'g*', markersize=15, label='Global minimum (3, 0.5)')\n",
    "    \n",
    "    ax.set_xlim([-4.5, 4.5])\n",
    "    ax.set_ylim([-4.5, 4.5])\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.legend()\n",
    "    ax.set_title('Beale Function: Gradient Descent vs Momentum')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing vanilla GD vs momentum\n",
    "start = np.array([-3.0, 3.0])\n",
    "\n",
    "#vanilla GD needs tiny steps to not explode\n",
    "gd_path = gradient_descent(start, df_beale, step_size=0.0001, num_steps=100)\n",
    "\n",
    "#momentum can take bigger steps and still converge\n",
    "momentum_path = gradient_descent_momentum(start, df_beale, step_size=0.001, num_steps=150, beta=0.95)\n",
    "\n",
    "visualize_beale(gd_path, momentum_path)\n",
    "\n",
    "print(f\"Vanilla GD final position: {gd_path[-1]}\")\n",
    "print(f\"Momentum final position: {momentum_path[-1]}\")\n",
    "print(f\"Global minimum: (3, 0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The visualization shows how momentum helps:\n",
    "\n",
    "1. **Vanilla GD (red)** barely moves - with such a small step size it would need thousands of iterations\n",
    "2. **Momentum (magenta)** makes much more progress toward the minimum\n",
    "\n",
    "The momentum term accumulates velocity in consistent directions while dampening oscillations. This is why optimizers like Adam (which uses momentum) are standard in deep learning - raw gradient descent is too slow and unstable for complex loss landscapes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
